{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinn-j/DataScienceBasics/blob/NLP_basics/Workingcode_Intent_Recognition_using_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "tf-12NCNYTET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c7np3u_akH4R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pyxwuqb8XD9T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collection:"
      ],
      "metadata": {
        "id": "wfz_UdNgYXil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sample_data/Intent.json', 'r') as f:\n",
        "\tdata = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(type(data['intents']))\n",
        "print(len(data['intents']))\n",
        "print(data['intents'][0].keys())\n",
        "data['intents'][-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onndG4I8XS2z",
        "outputId": "ca688048-14a5-4fe8-87d7-a69502091482"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['intents'])\n",
            "<class 'list'>\n",
            "22\n",
            "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'SelfAware',\n",
              " 'text': ['Can you prove you are self-aware',\n",
              "  'Can you prove you are self aware',\n",
              "  'Can you prove you have a conscious',\n",
              "  'Can you prove you are self-aware please',\n",
              "  'Can you prove you are self aware please',\n",
              "  'Can you prove you have a conscious please',\n",
              "  'prove you have a conscious'],\n",
              " 'responses': ['That is an interesting question, can you prove that you are?',\n",
              "  'That is an difficult question, can you prove that you are?',\n",
              "  'That depends, can you prove that you are?'],\n",
              " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
              " 'context': {'in': '', 'out': '', 'clear': False},\n",
              " 'entityType': 'NA',\n",
              " 'entities': []}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning:"
      ],
      "metadata": {
        "id": "TjVQp2QSYaw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(line):\n",
        "\tcleaned_line = ''\n",
        "\tfor char in line:\n",
        "\t\tif char.isalpha():\n",
        "\t\t\tcleaned_line += char\n",
        "\t\telse:\n",
        "\t\t\tcleaned_line += ' '\n",
        "\tcleaned_line = ' '.join(cleaned_line.split())\n",
        "\treturn cleaned_line\n"
      ],
      "metadata": {
        "id": "dPUGIAuNYNMP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:"
      ],
      "metadata": {
        "id": "vUjj5u07YdlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#list of intents\n",
        "intents = []\n",
        "unique_intents = []\n",
        "#all text data to create a corpus\n",
        "text_input= []\n",
        "#dictionary mapping intent with appropriate response\n",
        "response_for_intent = {}\n",
        "for intent in data['intents']:\n",
        "\t#list of unique intents\n",
        "\tif intent['intent'] not in unique_intents:\n",
        "\t\tunique_intents.append(intent['intent'])\n",
        "\tfor text in intent['text']:\n",
        "\t\t#cleaning is done before adding text to corpus\n",
        "\t\ttext_input.append(clean(text))\n",
        "\t\tintents.append(intent['intent'])\n",
        "\tif intent['intent'] not in response_for_intent:\n",
        "\t\tresponse_for_intent[intent['intent']] = []\n",
        "\tfor response in intent['responses']:\n",
        "\t\tresponse_for_intent[intent['intent']].append(response)\n"
      ],
      "metadata": {
        "id": "sAcTOWD1YPZm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Intent :\",intents[0])\n",
        "print(\"Number of Intent:\",len(intents))\n",
        "print(\"Sample Input:\", text_input[0])\n",
        "print('Length of text_input:',len(text_input))\n",
        "print(\"Sample Response: \", response_for_intent[intents[0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQEA9RSTYRY9",
        "outputId": "ad280298-6605-4f65-d933-d033b1dfe036"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent : Greeting\n",
            "Number of Intent: 143\n",
            "Sample Input: Hi\n",
            "Length of text_input: 143\n",
            "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Embedding"
      ],
      "metadata": {
        "id": "FawpKl0HYkF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='',oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(text_input)\n",
        "sequences = tokenizer.texts_to_sequences(text_input)\n",
        "padded_sequences = pad_sequences(sequences, padding='pre')\n",
        "print('Shape of Input Sequence:',padded_sequences.shape)\n",
        "padded_sequences[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6SZFLcEYm0k",
        "outputId": "7135d568-385b-4257-8d2a-fa0cfba175e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Sequence: (143, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction:"
      ],
      "metadata": {
        "id": "SkiA4OWbYp2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_to_index = {}\n",
        "categorical_target = []\n",
        "index = 0\n",
        "\n",
        "for intent in intents:\n",
        "\tif intent not in intent_to_index:\n",
        "\t\tintent_to_index[intent] = index\n",
        "\t\tindex += 1\n",
        "\tcategorical_target.append(intent_to_index[intent])\n",
        "\n",
        "num_classes = len(intent_to_index)\n",
        "print('Number of Intents :',num_classes)\n",
        "\n",
        "# Convert intent_to_index to index_to_intent\n",
        "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
        "index_to_intent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qxFXsSYqbB",
        "outputId": "468be70d-9e74-4aff-da07-7c0acee298fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intents : 22\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Greeting',\n",
              " 1: 'GreetingResponse',\n",
              " 2: 'CourtesyGreeting',\n",
              " 3: 'CourtesyGreetingResponse',\n",
              " 4: 'CurrentHumanQuery',\n",
              " 5: 'NameQuery',\n",
              " 6: 'RealNameQuery',\n",
              " 7: 'TimeQuery',\n",
              " 8: 'Thanks',\n",
              " 9: 'NotTalking2U',\n",
              " 10: 'UnderstandQuery',\n",
              " 11: 'Shutup',\n",
              " 12: 'Swearing',\n",
              " 13: 'GoodBye',\n",
              " 14: 'CourtesyGoodBye',\n",
              " 15: 'WhoAmI',\n",
              " 16: 'Clever',\n",
              " 17: 'Gossip',\n",
              " 18: 'Jokes',\n",
              " 19: 'PodBayDoor',\n",
              " 20: 'PodBayDoorResponse',\n",
              " 21: 'SelfAware'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding"
      ],
      "metadata": {
        "id": "6AEcTyx5YuBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_vec = tf.keras.utils.to_categorical(categorical_target,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tnum_classes=num_classes)\n",
        "categorical_vec = categorical_vec.astype('int32')\n",
        "\n",
        "print('Shape of Ca',categorical_vec.shape)\n",
        "categorical_vec[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2JjinKpYvTE",
        "outputId": "aad90e1a-4c50-4620-a5cf-0430fe28e08b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Ca (143, 22)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building:"
      ],
      "metadata": {
        "id": "U_49YMYnZaMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "embed_dim=300\n",
        "lstm_num=50\n",
        "output_dim=categorical_vec.shape[1]\n",
        "input_dim=len(unique_intents)\n",
        "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JItwU40DZaoy",
        "outputId": "5af28db5-ec3c-4e1d-a137-a4081b307912"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dimension :22,\n",
            "Output Dimension :22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\ttf.keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim),\n",
        "\ttf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1)),\n",
        "\ttf.keras.layers.Dense(lstm_num, activation='relu'),\n",
        "\ttf.keras.layers.Dropout(0.4),\n",
        "\ttf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "QMTPIpp6ZeFG",
        "outputId": "9009b38b-c8ad-4fc1-a2ea-f90dc849b562"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "41vmHSMlZ4eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHXANH-xZ6Jy",
        "outputId": "4dd6597f-9d77-4e9b-d499-70c8371bbcb1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c36eaa2d780>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "LbKkD9IaaBwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_inputs = [\"Hello\",\n",
        "\t\t\t\t\t\"my name is adam\",\n",
        "\t\t\t\t\t\"how are you?\",\n",
        "\t\t\t\t\t\"can you guess my name?\",\n",
        "\t\t\t\t\t\"Do you get me\",\"Adios\"]\n",
        "\n",
        "test_intents = [\"Greeting\",\n",
        "\t\t\t\t\"GreetingResponse\",\n",
        "\t\t\t\t\"CourtesyGreeting\",\n",
        "\t\t\t\t\"CurrentHumanQuery\",\n",
        "\t\t\t\t\"UnderstandQuery\",\n",
        "\t\t\t\t\"GoodBye\"]\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_inputs)\n",
        "test_padded_sequences = pad_sequences(test_sequences, padding='pre')\n",
        "test_labels = np.array([unique_intents.index(intent) for intent in test_intents])\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFzzhkKsaDHu",
        "outputId": "6a7ea9a8-5505-429b-b5a2-44d928fdb290"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.3627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "i5pfnahqaJVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response(sentence):\n",
        "\tsent_tokens = []\n",
        "\t# Split the input sentence into words\n",
        "\twords = sentence.split()\n",
        "\t# Convert words to their corresponding word indices\n",
        "\tfor word in words:\n",
        "\t\tif word in tokenizer.word_index:\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index[word])\n",
        "\t\telse:\n",
        "\t\t\t# Handle unknown words\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index['<unk>'])\n",
        "\tsent_tokens = tf.expand_dims(sent_tokens, 0)\n",
        "\t#predict numerical category\n",
        "\tpred = model(sent_tokens)\n",
        "\t#category to intent\n",
        "\tpred_class = np.argmax(pred.numpy(), axis=1)\n",
        "\t# random response to that intent\n",
        "\treturn random.choice(\n",
        "\t\tresponse_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]\n"
      ],
      "metadata": {
        "id": "Mw66BcEbaKjC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbots: Intent Recognition"
      ],
      "metadata": {
        "id": "bqQcNOZTaOgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "while True:\n",
        "\tquery = input('You: ')\n",
        "\tif query.lower() == 'quit':\n",
        "\t\tbreak\n",
        "\tbot_response, typ = response(query)\n",
        "\tprint('Geek: {} -- TYPE: {}'.format(bot_response, typ))\n",
        "\tprint()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZTsMx4haQ4r",
        "outputId": "57837ae1-6a78-41ac-da86-2da34ffe41ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: hi\n",
            "Geek: Hi human, please tell me your GeniSys user -- TYPE: Greeting\n",
            "\n",
            "You: name\n",
            "Geek: You may call me Geni -- TYPE: NameQuery\n",
            "\n",
            "You: help me\n",
            "Geek: Your name is  <HUMAN>, how can I help you? -- TYPE: CurrentHumanQuery\n",
            "\n",
            "You: book\n",
            "Geek: Let me see -- TYPE: WhoAmI\n",
            "\n",
            "You: whoami\n",
            "Geek: Please look at the camera -- TYPE: WhoAmI\n",
            "\n",
            "You: ok\n",
            "Geek: No problem! -- TYPE: Thanks\n",
            "\n"
          ]
        }
      ]
    }
  ]
}